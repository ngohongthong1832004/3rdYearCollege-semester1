{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset\n",
    "\n",
    "# Fit three classifiers\n",
    "\n",
    "# To make a prediction - pick max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "considerable-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599453\n",
      "Epoch 100, Loss: 0.5301551939171789\n",
      "Epoch 200, Loss: 0.4349624699607965\n",
      "Epoch 300, Loss: 0.36471407122797755\n",
      "Epoch 400, Loss: 0.3117165875250556\n",
      "Epoch 500, Loss: 0.27083106039330734\n",
      "Epoch 600, Loss: 0.23861224499926478\n",
      "Epoch 700, Loss: 0.21272701820012996\n",
      "Epoch 800, Loss: 0.1915682411818194\n",
      "Epoch 900, Loss: 0.1740068473916435\n",
      "Predicted class for point [1 2]: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hàm dự đoán\n",
    "def predict(X, weights):\n",
    "    z = np.dot(X, weights)  # Tính tích vô hướng\n",
    "    return sigmoid(z)\n",
    "\n",
    "# Hàm mất mát (Binary Cross-Entropy Loss)\n",
    "def loss(y_true, y_pred):\n",
    "    # Tránh log(0) bằng cách thêm một giá trị nhỏ (epsilon)\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Huấn luyện Logistic Regression bằng Gradient Descent\n",
    "def train_logistic_regression(X, y, learning_rate=0.01, epochs=1000):\n",
    "    # Số lượng mẫu và số lượng đặc trưng\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Khởi tạo trọng số\n",
    "    weights = np.zeros(n_features)\n",
    "    \n",
    "    # Huấn luyện qua các epoch\n",
    "    for epoch in range(epochs):\n",
    "        # Dự đoán đầu ra dựa trên trọng số hiện tại\n",
    "        y_pred = predict(X, weights)\n",
    "        \n",
    "        # Tính gradient của hàm mất mát theo trọng số\n",
    "        gradient = np.dot(X.T, (y_pred - y)) / n_samples\n",
    "        \n",
    "        # Cập nhật trọng số\n",
    "        weights -= learning_rate * gradient\n",
    "        \n",
    "        # Tùy chọn: In ra mất mát sau mỗi vài epoch\n",
    "        if epoch % 100 == 0:\n",
    "            current_loss = loss(y, y_pred)\n",
    "            print(f\"Epoch {epoch}, Loss: {current_loss}\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Dữ liệu đầu vào X và y\n",
    "X = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Thêm bias (hệ số tự do) vào X bằng cách thêm cột 1s\n",
    "X_bias = np.c_[np.ones((X.shape[0], 1)), X]  # Thêm cột 1 vào đầu của X\n",
    "\n",
    "# Huấn luyện mô hình Logistic Regression\n",
    "weights = train_logistic_regression(X_bias, y, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "# Dự đoán cho điểm mới\n",
    "new_point = np.array([1, 2])  # Ví dụ, dữ liệu đầu vào mới\n",
    "new_point_bias = np.r_[1, new_point]  # Thêm bias vào điểm mới\n",
    "predicted_prob = predict(new_point_bias, weights)\n",
    "\n",
    "# Dự đoán lớp cuối cùng\n",
    "predicted_class = 1 if predicted_prob >= 0.5 else 0\n",
    "print(f\"Predicted class for point {new_point}: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54271695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
